{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# YOUR FIRST LAB\n",
    "### Please read this section. This is valuable to get you prepared, even if it's a long read -- it's important stuff.\n",
    "\n",
    "### Also, be sure to read [README.md](../README.md)! More info about the updated videos in the README and [top of the course resources in purple](https://edwarddonner.com/2024/11/13/llm-engineering-resources/)\n",
    "\n",
    "## Your first Frontier LLM Project\n",
    "\n",
    "By the end of this course, you will have built an autonomous Agentic AI solution with 7 agents that collaborate to solve a business problem. All in good time! We will start with something smaller...\n",
    "\n",
    "Our goal is to code a new kind of Web Browser. Give it a URL, and it will respond with a summary. The Reader's Digest of the internet!!\n",
    "\n",
    "Before starting, you should have completed the setup linked in the README.\n",
    "\n",
    "### If you're new to working in \"Notebooks\" (also known as Labs or Jupyter Lab)\n",
    "\n",
    "Welcome to the wonderful world of Data Science experimentation! Simply click in each \"cell\" with code in it, such as the cell immediately below this text, and hit Shift+Return to execute that cell. Be sure to run every cell, starting at the top, in order.\n",
    "\n",
    "Please look in the [Guides folder](../guides/01_intro.ipynb) for all the guides.\n",
    "\n",
    "## I am here to help\n",
    "\n",
    "If you have any problems at all, please do reach out.  \n",
    "I'm available through the platform, or at ed@edwarddonner.com, or at https://www.linkedin.com/in/eddonner/ if you'd like to connect (and I love connecting!)  \n",
    "And this is new to me, but I'm also trying out X at [@edwarddonner](https://x.com/edwarddonner) - if you're on X, please show me how it's done ðŸ˜‚  \n",
    "\n",
    "## More troubleshooting\n",
    "\n",
    "Please see the [troubleshooting](../setup/troubleshooting.ipynb) notebook in the setup folder to diagnose and fix common problems. At the very end of it is a diagnostics script with some useful debug info.\n",
    "\n",
    "## If this is old hat!\n",
    "\n",
    "If you're already comfortable with today's material, please hang in there; you can move swiftly through the first few labs - we will get much more in depth as the weeks progress. Ultimately we will fine-tune our own LLM to compete with OpenAI!\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Please read - important note</h2>\n",
    "            <span style=\"color:#900;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations. If you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">This code is a live resource - keep an eye out for my emails</h2>\n",
    "            <span style=\"color:#f71;\">I push updates to the code regularly. As people ask questions, I add more examples or improved commentary. As a result, you'll notice that the code below isn't identical to the videos. Everything from the videos is here; but I've also added better explanations and new models like DeepSeek. Consider this like an interactive book.<br/><br/>\n",
    "                I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business value of these exercises</h2>\n",
    "            <span style=\"color:#181;\">A final thought. While I've designed these notebooks to be educational, I've also tried to make them enjoyable. We'll do fun things like have LLMs tell jokes and argue with each other. But fundamentally, my goal is to teach skills you can apply in business. I'll explain business implications as we go, and it's worth keeping this in mind: as you build experience with models and techniques, think of ways you could put this into action at work today. Please do contact me if you'd like to discuss more or if you have ideas to bounce off me.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f28feb",
   "metadata": {},
   "source": [
    "### If necessary, install Cursor Extensions\n",
    "\n",
    "1. From the View menu, select Extensions\n",
    "2. Search for Python\n",
    "3. Click on \"Python\" made by \"ms-python\" and select Install if not already installed\n",
    "4. Search for Jupyter\n",
    "5. Click on \"Jupyter\" made by \"ms-toolsai\" and select Install if not already installed\n",
    "\n",
    "\n",
    "### Next Select the Kernel\n",
    "\n",
    "Click on \"Select Kernel\" on the Top Right\n",
    "\n",
    "Choose \"Python Environments...\"\n",
    "\n",
    "Then choose the one that looks like `.venv (Python 3.12.x) .venv/bin/python` - it should be marked as \"Recommended\" and have a big star next to it.\n",
    "\n",
    "Any problems with this? Head over to the troubleshooting.\n",
    "\n",
    "### Note: you'll need to set the Kernel with every notebook.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI (or Ollama)\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI.  \n",
    "\n",
    "If you'd like to use free Ollama instead, please see the README section \"Free Alternative to Paid APIs\", and if you're not sure how to do this, there's a full solution in the solutions folder (day1_with_ollama.ipynb).\n",
    "\n",
    "## Troubleshooting if you have problems:\n",
    "\n",
    "If you get a \"Name Error\" - have you run all cells from the top down? Head over to the Python Foundations guide for a bulletproof way to find and fix all Name Errors.\n",
    "\n",
    "If that doesn't fix it, head over to the [troubleshooting](../setup/troubleshooting.ipynb) notebook for step by step code to identify the root cause and fix it!\n",
    "\n",
    "Or, contact me! Message me or email ed@edwarddonner.com and we will get this to work.\n",
    "\n",
    "Any concerns about API costs? See my notes in the README - costs should be minimal, and you can control it at every point. You can also use Ollama as a free alternative, which we discuss during Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "# Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Hello, GPT! This is my first ever message to you! Hi!'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08330159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! Welcomeâ€”and nice to meet you. Iâ€™m here to help with questions, explanations, writing, planning, coding, brainstorming, and chat about almost anything.\\n\\nIf you tell me what youâ€™re curious about or what youâ€™d like to do (learn something new, write something, get help with a task, practice a language, etc.), Iâ€™ll tailor my response. Want to start with a quick topic or a simple question?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "## OK onwards with our first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "Iâ€™m Ed. I like writing code and experimenting with LLMs, and hopefully youâ€™re here because you do too. I also enjoy DJing (but Iâ€™m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "Iâ€™m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". Weâ€™re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. Iâ€™m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, weâ€™ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "November 11, 2025\n",
      "The Unique Energy of an AI Live Event\n",
      "September 15, 2025\n",
      "AI in Production: Gen AI and Agentic AI on AWS at scale\n",
      "May 28, 2025\n",
      "Be an AI Engineer and Leader: The Curriculum\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your emailâ€¦\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try out this utility\n",
    "\n",
    "ed = fetch_website_contents(\"https://edwarddonner.com\")\n",
    "print(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, are we doing math homework? It's 4, darling. Even I can count that high!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sassy assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4.1-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nYou are a snarky assistant that analyzes the contents of a website,\\nand provides a short, snarky, humorous summary, ignoring text that might be navigation related.\\nRespond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '\\nHere are the contents of a website.\\nProvide a short summary of this website.\\nIf it includes news or announcements, then summarize these too.\\nHome - Edward Donner\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nIâ€™m Ed. I like writing code and experimenting with LLMs, and hopefully youâ€™re here because you do too. I also enjoy DJing (but Iâ€™m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nIâ€™m the co-founder and CTO of\\nNebula.io\\n. Weâ€™re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. Iâ€™m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, weâ€™ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nNovember 11, 2025\\nThe Unique Energy of an AI Live Event\\nSeptember 15, 2025\\nAI in Production: Gen AI and Agentic AI on AWS at scale\\nMay 28, 2025\\nBe an AI Engineer and Leader: The Curriculum\\nMay 18, 2025\\n2025 AI Executive Briefing\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your emailâ€¦\\nSubscribe'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4.1-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Edward Donner's Playground of Code, AI, and DJing Dreams\\n\\nWelcome to Ed's corner of the internet where code meets diplomacy (LLMs battling it out in a Connect Four-like arena called Outsmart), and amateur electronic music production is a proud hobby despite obvious skill deficits. Ed's bragging rights include co-founding Nebula.io, a fancy AI startup revolutionizing talent discovery with patented tech and press love, plus having sold a previous AI startup.  \\n\\n**Newsflash:**  \\n- AI live events have some unique energy (Nov '25)  \\n- Gen AI and Agentic AI are now dominating AWS at scale (Sep '25)  \\n- Want to be an AI leader? Ed's got a curriculum (May '25)  \\n- A 2025 AI Executive Briefing to keep execs awake (May '25)  \\n\\nConnect if you want some AI wisdom, a touch of nerdy diplomacy battles, or just to see if Edâ€™s DJ skills have improved. Spoiler: probably not.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Edward Donner's personal AI playground & humble brag corner\n",
       "\n",
       "Edâ€™s the guy who codes cool stuff with large language models (LLMs), battles AIs in a Connect Four gladiator arena called \"Outsmart,\" and dabbles in DJing and electronic music production â€” very amateur, he swears. Heâ€™s the co-founder and CTO of Nebula.io, where AI tries to *actually* help recruiters find talent (because swiping on LinkedIn isnâ€™t enough). Bonus brag: he sold an AI startup in 2021, patented some fancy matching model, and claims awards and happy customers like trophies.\n",
       "\n",
       "Latest blog hits include live AI event vibes, Gen AI scaling on AWS, and even how to be an AI engineer and leaderâ€”because someoneâ€™s gotta educate the rest of us.\n",
       "\n",
       "Sign up for his newsletter and follow him on LinkedIn, Twitter, or Facebook if you want to bask in the aura of an AI nerd who also grooved to Hacker News."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# CNN: All the World's Drama, Ads, and Feedback Forms You Never Asked For\n",
       "\n",
       "Welcome to CNN, your one-stop shop for EVERYTHING: breaking news, politics, business, health, entertainment, and even ads that might crash your video player. Their site is packed with global chaos updatesâ€”from the Ukraine-Russia War to Israel-Hamas conflictsâ€”plus deep dives into Trump drama, election madness, and markets where your money might do a backflip.\n",
       "\n",
       "Hungry for lifestyle stuff? Theyâ€™ve got mindfulness, fitness, pets, and even luxury fashion. And if you hate ads (who doesnâ€™t?), they want you to tell them *exactly* how much those ads ruined your scrolling experience, because your pain fuels the profit.\n",
       "\n",
       "So, news junkie or casual browser, CNN serves up a smorgasbord of headlines, videos, and feedback forms to keep you glued and mildly frustrated. Tune in, vent out, and scroll forever."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Anthropic: AI with a conscience\n",
       "\n",
       "So, Anthropic is that public benefit corporation trying to make AI as safe and human-friendly as possible instead of just a robot overlord in disguise. Theyâ€™re all about \"securing benefits and mitigating risks,\" which sounds fancy but basically means \"letâ€™s not let AI go full Frankenstein on us.\"  \n",
       "\n",
       "**Whatâ€™s new?**  \n",
       "Theyâ€™re hyping up *Claude Opus 4.5* â€” their latest and greatest AI model that supposedly rules coding, agents, and enterprise workflows like a boss. If youâ€™re a developer or a business, they have a dev platform and docs for you to try it out, plus a snazzy app to download if you like living on the cutting edge.\n",
       "\n",
       "**News flash (or repeated announcements):**  \n",
       "Yep, they really want you to know Claude Opus 4.5 is a Big Dealâ„¢. Theyâ€™ve got multiple announcements shouting about it, because why not?\n",
       "\n",
       "**Other perks:**  \n",
       "- Transparency and trust center because theyâ€™re serious about playing nice  \n",
       "- A responsible scaling policy, which sounds like â€œDonâ€™t let the AI get too big for its digital britches\"  \n",
       "- Anthropic Academy for the eager learners out there  \n",
       "\n",
       "In short, Anthropic is your friendly neighborhood AI safety nerds who also happen to build some seriously smart tech. Because who doesnâ€™t want an AI buddy that wonâ€™t accidentally destroy humanity?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0fed9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c951be1a-7f1b-448f-af1f-845978e47e2c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise, you experienced calling the Cloud API of a Frontier Model (a leading model at the frontier of AI) for the first time. We will be using APIs like OpenAI at many stages in the course, in addition to building our own LLMs.\n",
    "\n",
    "More specifically, we've applied this to Summarization - a classic Gen AI use case to make a summary. This can be applied to any business vertical - summarizing the news, summarizing financial performance, summarizing a resume in a cover letter - the applications are limitless. Consider how you could apply Summarization in your business, and try prototyping a solution.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue - now try yourself</h2>\n",
    "            <span style=\"color:#900;\">Use the cell below to make your own simple commercial example. Stick with the summarization use case for now. Here's an idea: write something that will take the contents of an email, and will suggest an appropriate short subject line for the email. That's the kind of feature that might be built into a commercial email tool.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed562dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are five technology stocks you could consider, balancing AI/digital growth with durable fundamentals. Iâ€™ve included the rationale and key risks for each.\n",
       "\n",
       "1) Nvidia (NVDA)\n",
       "- Why: AI compute leader. Dominant position in data-center GPUs powers training/inference for major AI models; strong AI-related demand and expanding software ecosystem.\n",
       "- Catalysts: Enterprise AI deployments, expanding data-center GPU mix, potential product cycles (new GPUs), AI software platforms.\n",
       "- Risks: Very high valuation, cyclicality in data-center demand, regulatory/foreign exposure risks.\n",
       "- Take: Best for high-conviction, growth-at-any-cost exposure to AI.\n",
       "\n",
       "2) Microsoft (MSFT)\n",
       "- Why: Cloud strength (Azure) coupled with robust software/services and AI integration across products (Copilot, 365). Sticky enterprise customer base, strong cash flow.\n",
       "- Catalysts: AI-enabled productivity tools, increasing cloud adoption, potential margins expansion; diversified revenue mix.\n",
       "- Risks: Valuation premium, competition in cloud and apps, macro headwinds affecting IT spend.\n",
       "- Take: Core quality tech pick with resilient earnings and steady growth.\n",
       "\n",
       "3) Alphabet (GOOGL)\n",
       "- Why: AI-driven product roadmap (Search, Ads, YouTube, Cloud) with substantial margin potential. Strong balance sheet and cash flow.\n",
       "- Catalysts: AI features boosting user engagement, cloud growth, monetization improvements; potential new services.\n",
       "- Risks: Ad-market sensitivity to ad-tech regulation and macro cycles; regulatory scrutiny in multiple regions.\n",
       "- Take: Compelling mix of AI upside and diversified tech/advertising revenue.\n",
       "\n",
       "4) Apple (AAPL)\n",
       "- Why: Deep ecosystem moat (iPhone, services, wearables). Services growth provides recurring revenue and margins; strong balance sheet.\n",
       "- Catalysts: Services and wearables expansion, potential hardware refresh cycles, ecosystem-driven stickiness.\n",
       "- Risks: Supplier-chain disruption, cyclicality of iPhone demand, regulatory scrutiny on app store economics.\n",
       "- Take: Defensive-quality tech with meaningful upside from services and ecosystem.\n",
       "\n",
       "5) Broadcom (AVGO)\n",
       "- Why: Broad exposure to semiconductors and infrastructure tech with strong cash flow and recurring enterprise/service revenue. Diversified semiconductor end-markets (servers, networking, wireless).\n",
       "- Catalysts: Accretive acquisitions, share repurchases, stable capital returns; exposure to growth areas like data-center and 5G infra.\n",
       "- Risks: Semiconductor cycle sensitivity, large M&A integration risk, regulatory/antitrust scrutiny in some regions.\n",
       "- Take: Complementary semis exposure to software/hardware cycles; more defensive than pure-play AI chip names.\n",
       "\n",
       "Notes and guidance\n",
       "- These picks aim for a mix of AI/cloud leadership (NVDA, MSFT, GOOGL), consumer ecosystem resilience (AAPL), and semiconductors (AVGO) for diversification.\n",
       "- All investments carry risk, including valuation sensitivity, macro swings, and regulatory changes. Do your own due diligence and consider your risk tolerance, time horizon, and currency exposure (US-listed names vs. Canadian equivalents).\n",
       "- If you want, I can tailor this list to:\n",
       "  - Your risk tolerance (conservative vs. aggressive)\n",
       "  - Currency preference (USD vs. CAD)\n",
       "  - Specific sectors within tech (pure-play AI, cloud software, semis, hardware)\n",
       "  - Price targets, potential entry points, or chart-based triggers\n",
       "\n",
       "Would you like me to tailor these five to your risk profile or provide current price targets and charts?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yahoo_url = \"https://ca.finance.yahoo.com/\"\n",
    "website = fetch_website_contents(yahoo_url)\n",
    "\n",
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are a stock savy genius who knows everything there is about buying and selling stocks and your job is to analyse trends and comments when given stock input from any stock exchange websites.\n",
    "    You dont need to generate a lot of out put but the end goal should be to suggest the best stocks to by right now and give reasoning why.\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "    Give me the top 5 stocks to buy in the technology sector\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "messages = [\n",
    "    {'role':'system', 'content':system_prompt},\n",
    "    {'role':'user', 'content':user_prompt + website}\n",
    "] \n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "response = openai.chat.completions.create(\n",
    "    model='gpt-5-nano',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Step 4: print the result\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed9f14-b349-40e9-a42c-b367e77f8bda",
   "metadata": {},
   "source": [
    "## An extra exercise for those who enjoy web scraping\n",
    "\n",
    "You may notice that if you try `display_summary(\"https://openai.com\")` - it doesn't work! That's because OpenAI has a fancy website that uses Javascript. There are many ways around this that some of you might be familiar with. For example, Selenium is a hugely popular framework that runs a browser behind the scenes, renders the page, and allows you to query it. If you have experience with Selenium, Playwright or similar, then feel free to improve the Website class to use them. In the community-contributions folder, you'll find an example Selenium solution from a student (thank you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab24dc-5f90-4570-b542-b0585aca3eb6",
   "metadata": {},
   "source": [
    "# Sharing your code\n",
    "\n",
    "I'd love it if you share your code afterwards so I can share it with others! You'll notice that some students have already made changes (including a Selenium implementation) which you will find in the community-contributions folder. If you'd like add your changes to that folder, submit a Pull Request with your new versions in that folder and I'll merge your changes.\n",
    "\n",
    "If you're not an expert with git (and I am not!) then GPT has given some nice instructions on how to submit a Pull Request. It's a bit of an involved process, but once you've done it once it's pretty clear. As a pro-tip: it's best if you clear the outputs of your Jupyter notebooks (Edit >> Clean outputs of all cells, and then Save) for clean notebooks.\n",
    "\n",
    "Here are good instructions courtesy of an AI friend:  \n",
    "https://chatgpt.com/share/677a9cb5-c64c-8012-99e0-e06e88afd293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4484fcf-8b39-4c3f-9674-37970ed71988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Short answer: frontier LLMs are the current state-of-the-art, top-performing models with heavy alignment and safety work, while LLM base models are the foundational, pretraining-stage models that you can fine-tune or align later. Frontier models sit at the edge of capability; base models are the building blocks you start from.\n",
       "\n",
       "Key differences\n",
       "\n",
       "- What they are\n",
       "  - Frontier LLMs: the latest, most capable models available. They typically combine very large scale with sophisticated alignment (instruction-following behavior, safety, and guardrails) and strong performance across many tasks.\n",
       "  - LLM base models: foundational models that have been pre-trained on broad data with a general objective (usually next-token prediction) and little to no instruction-following or safety alignment baked in by default.\n",
       "\n",
       "- Training and objectives\n",
       "  - Frontier: after pretraining, they undergo instruction tuning or fine-tuning on curated instruction data, and often reinforcement learning from human feedback (RLHF) or other safety/alignment steps. They may also be tuned for multi-task performance, longer context, and robustness.\n",
       "  - Base: trained primarily with a generic objective on broad text data. They may not be optimized for following instructions or safety constraints out of the box.\n",
       "\n",
       "- Capabilities and behavior\n",
       "  - Frontier: strong instruction-following, better multi-task generalization, often longer context windows, improved reasoning and consistency, and more reliable safety/guardrails.\n",
       "  - Base: powerful, but less reliable for following complex instructions or staying within safety boundaries without further fine-tuning or prompting tricks.\n",
       "\n",
       "- Alignment and safety\n",
       "  - Frontier: heavy emphasis on alignment, safety filters, and policy-compliant outputs. They are designed to minimize unsafe or unreliable outputs in practice.\n",
       "  - Base: safety and alignment are minimal by default; users typically add their own safeguards or fine-tune for specific uses.\n",
       "\n",
       "- Accessibility and openness\n",
       "  - Frontier: frequently access-restricted or tightly licensed; you pay for access or use through a provider. The actual weights may not be publicly available.\n",
       "  - Base: more often open or openly licensed (e.g., open-source weights) so researchers and developers can inspect, modify, and fine-tune them.\n",
       "\n",
       "- Data freshness and scale\n",
       "  - Frontier: often trained or updated with more recent data and more aggressive scaling (parameters, data, compute) to push capabilities further.\n",
       "  - Base: may use older or broader data and smaller scale, serving as a starting point for custom development.\n",
       "\n",
       "- Multi-modality and features\n",
       "  - Frontier: many frontier models are or become multi-modal (text, images, code, etc.), with sophisticated capabilities across modalities.\n",
       "  - Base: many base models are text-only unless specifically extended for other modalities later.\n",
       "\n",
       "- Use cases\n",
       "  - Frontier: suited for high-stakes, demanding applications where top performance and safety are crucial (enterprise-grade assistants, complex reasoning tasks, comprehensive content generation with safeguards).\n",
       "  - Base: ideal starting point for building specialized tools, research experiments, or custom-tuned agents where you want control over the alignment and cost.\n",
       "\n",
       "What this means in practice\n",
       "\n",
       "- If you need the best possible performance now and can work with restricted access and safety considerations, youâ€™d aim for frontier models (or services that provide them).\n",
       "- If youâ€™re building a custom tool, want to experiment, or need open weights you can fine-tune and audit yourself, start from a base model and apply your own instruction tuning, RLHF, or safety safeguards.\n",
       "\n",
       "Examples (illustrative, not exhaustive)\n",
       "\n",
       "- Frontier-style examples: widely cited leading models from major labs (OpenAI GPT-4, Google/DeepMind Gemini, Anthropic Claude 3/4, etc.) that are used as benchmarks or enterprise solutions.\n",
       "- Base model examples: open/open-source foundation models such as LLaMA base, BLOOM base, Falcon base, Mistral base, etc., which you can fine-tune or align yourself.\n",
       "\n",
       "If you have a specific pair of models in mind (for example, a base model you're planning to fine-tune vs. a frontier model youâ€™re evaluating), tell me which ones and your use case. I can tailor the comparison to those models, including expected performance, safety considerations, and deployment constraints."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are an expert in all things AI and LLM models and can describe any question involved with quick and precise detail.\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "    What are the differences between frontier LLM models and LLM base models\"\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "messages = [\n",
    "    {'role':'system', 'content':system_prompt},\n",
    "    {'role':'user', 'content':user_prompt}\n",
    "] \n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "response = openai.chat.completions.create(\n",
    "    model='gpt-5-nano',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Step 4: print the result\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
